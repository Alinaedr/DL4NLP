{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Chapter 3: Text Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.1 Embeddings\n",
    "\n",
    "Embeddings are procedures that turn input data into vectors.  Recall from chapter 1 that there are 2 kinds:\n",
    "* Representational embeddings are designed by hand and thus human-interpretable.\n",
    "* Operational embeddings are learned from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import codecs\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.1.1 Embed by Hand: Representational Embeddings\n",
    "**one-hot embeddings**\n",
    "Every element of this vector embedding is zero, except at a single meaningful index.\n",
    "<img src=\"images/oneHot.png/\">\n",
    "\n",
    "Given the embedding above:\n",
    "The word _cat_ is represented by the vector $ [0, 1, 0, 0, 0, 0 ]$\n",
    "The word _sat_ is represented by the vector $ [0, 0, 1, 0,0, 0, ]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0, 0, 1])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot(lexicon, word):\n",
    "    '''\n",
    "\n",
    "\n",
    "    :param lexicon: A sentence string\n",
    "    :param word: a string\n",
    "    :return: np.array one-hot vector representing the word from the given lexicon\n",
    "    '''\n",
    "    lexicon = np.array(lexicon.split(' ')) # split sentence into words\n",
    "    return np.multiply(lexicon == word, 1) # multiply turns True/False into integers 1, 0\n",
    "\n",
    "lex = 'want to go swim at the beach'\n",
    "\n",
    "one_hot(lex, 'beach' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ideally, words that are related to each other will generally lie close to each other in vector space, but note below that there spatial distance does not make sense from a linguistic perspective since different one-hot vectors only differ by just one bit.\n",
    "As such one-hot embeddings are used when distance-based similarity does not come into play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between \"beach\" and \"swim\": 1.4142135623730951\n",
      "distance between \"beach\" and \"want\": 1.4142135623730951\n"
     ]
    }
   ],
   "source": [
    "a = one_hot(lex, 'beach')\n",
    "b = one_hot(lex, 'swim')\n",
    "c = one_hot(lex, 'want')\n",
    "print(f'distance between \\\"beach\\\" and \\\"swim\\\": {np.linalg.norm(a - b)}')\n",
    "print(f'distance between \\\"beach\\\" and \\\"want\\\": {np.linalg.norm(a - c)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.1.1 Learning to Embed: Procedural embeddings\n",
    "Keras Embeddings layers deploy a matrix of weights that are optimized (like a mini single layer network) using a loss function.\n",
    "The implicit, default loss function is one that maximizes the distinctiveness of vector representations.\n",
    "\n",
    "The embedding below generates, for every array of 10 integers (a row in the input matrix), a 10x8 matrix consisting of 8-dimensional values, one for every integer in the integer array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "input dim: (10, 10)\n",
      "output dim: (10, 10, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-20 15:56:35.744723: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-20 15:56:35.745676: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 10. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential() # create the model container\n",
    "model.add(Embedding(input_dim=100, output_dim=8, input_length=10))   # add an embedding for 100 integers, arranged in blocks of 10\n",
    "input_array = np.random.randint(100, size=(10, 10)) # a random input\n",
    "model.compile('rmsprop', 'mse') # “compile the model, setting the loss function to 'mean squared error', and using the rmsprop optimizer. ”\n",
    "output_array = model.predict(input_array) # generate embeddings\n",
    "print(f'input dim: {input_array.shape}')\n",
    "print(f'output dim: {output_array.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Applied to text, we can represent a set of documents as a vector of integers and create a standard embedding of these documents in a similar way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chuck': 21, 'berry': 11, 'rolled': 74, 'over': 67, 'everyone': 27, 'who': 97, 'came': 15, 'before': 10, 'him': 41, 'and': 5, 'turned': 90, 'up': 92, 'after': 1, 'we': 96, 'll': 53, 'miss': 57, 'you': 102, 'help': 38, 'protect': 72, 'the': 85, 'progress': 71, 've': 93, 'made': 54, 'in': 43, 'helping': 39, 'millions': 56, 'of': 63, 'americans': 4, 'get': 32, 'covered': 24, 'let': 52, 'leave': 51, 'our': 66, 'children': 20, 'grandchildren': 34, 'planet': 70, 'that': 84, 'healthier': 37, 'than': 83, 'one': 65, 'have': 36, 'today': 88, 'american': 3, 'people': 69, 'are': 6, 'waiting': 94, 'for': 29, 'senate': 75, 'leaders': 50, 'to': 87, 'do': 25, 'their': 86, 'jobs': 46, 'must': 58, 'take': 82, 'bold': 12, 'steps': 81, 'now': 62, 'climate': 22, 'change': 18, 'is': 44, 'already': 2, 'impacting': 42, 'don': 26, 'forget': 30, 'watch': 95, 'larry': 48, 'king': 47, 'tonight': 89, 'ivanka': 45, 'on': 64, 'twitter': 91, 'can': 16, 'follow': 28, 'her': 40, 'last': 49, 'night': 61, 'melania': 55, 'attended': 8, 'skating': 79, 'with': 99, 'stars': 80, 'gala': 31, 'at': 7, 'wollman': 100, 'rink': 73, 'central': 17, 'park': 68, 'ability': 0, 'work': 101, 'should': 77, 'but': 14, 'government': 33, 'happy': 35, 'send': 76, 'checks': 19, 'will': 98, 'be': 9, 'signing': 78, 'copies': 23, 'my': 59, 'new': 60, 'book': 13}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "docs=[\"Chuck Berry rolled over everyone who came before him ? and turned up everyone who came after. We'll miss you\",\n",
    "      \"Help protect the progress we've made in helping millions of Americans get covered.\",\n",
    "      \"Let's leave our children and grandchildren a planet that's healthier than the one we have today.\",\n",
    "      \"The American people are waiting for Senate leaders to do their jobs.\",\n",
    "      \"We must take bold steps now ? climate change is already impacting millions of people.\",\n",
    "      \"Don't forget to watch Larry King tonight\",\n",
    "      \"Ivanka is now on Twitter - You can follow her\",\n",
    "      \"Last night Melania and I attended the Skating with the Stars Gala at Wollman Rink in Central Park\",\n",
    "      \"People who have the ability to work should. But with the government happy to send checks\",\n",
    "      \"I will be signing copies of my new book\"]\n",
    "\n",
    "docs=[d.lower() for d in docs] # make everything lower case\n",
    "\n",
    "count_vect = CountVectorizer().fit(docs) # maps every word to a unique arbitrary integer from the vocabulary\n",
    "tokenizer = count_vect.build_tokenizer() # initialize a tokenizer\n",
    "\n",
    "print(count_vect.vocabulary_)\n",
    "\n",
    "\n",
    "\n",
    "input_array=[]\n",
    "for doc in docs:\n",
    "    x=[]\n",
    "    for token in tokenizer(doc): #tokenizer(doc) just splits the string on white spaces to get a list of word strings\n",
    "        x.append(count_vect.vocabulary_.get(token)) # get the integer from the vocabulary assigned to each word in the doc\n",
    "    input_array.append(x)\n",
    "\n",
    "\n",
    "max_len=max([len(d) for d in input_array]) # max length of document\n",
    "input_array=pad_sequences(input_array, maxlen=max_len, padding='post') # pad with zeros so all vectors are the same length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can visualize the vector embeddings with the well-known visualization algorithm T-SNE (MaatenHinton2008). This algorithm maps high-dimensional vectors to lower-dimensional planes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/sklearn/manifold/t_sne.py:344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  error = np.finfo(np.float).max\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/sklearn/manifold/t_sne.py:345: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  best_error = np.finfo(np.float).max\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/sklearn/manifold/t_sne.py:344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  error = np.finfo(np.float).max\n",
      "/Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/sklearn/manifold/t_sne.py:345: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  best_error = np.finfo(np.float).max\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tsne_plot(model,max_words=200):\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    n=0\n",
    "    for word in model:\n",
    "        if n<max_words:\n",
    "            tokens.append(model[word])\n",
    "            labels.append(word)\n",
    "            n+=1\n",
    "\n",
    "\n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=10000, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(200, 8, input_length=20))\n",
    "#input_array = np.random.randint(100, size=(10, 10))\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "\n",
    "M={}\n",
    "for i in range(len(input_array)):\n",
    "    for j in range(len(input_array[i])):\n",
    "        M[input_array[i][j]]=output_array[i][j]\n",
    "\n",
    "tsne_plot(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " - so a lexicon is represented by a vocabulary that maps words to integers.\n",
    " - a single word is represented by an _integer_.\n",
    " - each _integer_ is then represented by the output of `model.predict()`, which gives an 8-dimensional array\n",
    "So each word is represented by this 8-dim vector in model output space.\n",
    "\n",
    "Note that spatial distance in the plot above does not reflect any semantic differences because our choice of optimizer `(rmsprop)` for the Embed layer didn't account for this.\n",
    "\n",
    "**Training a word embedding**\n",
    "\n",
    "with training of the Embedding layer, words should be vectorized such that _they contribute maximally to discerning documents with positive sentiment from those with negative sentiment._\n",
    "In other words, the word embeddings that are learned are optimized in the context of a specific task.\n",
    "\n",
    "**Optimization of a Keras embedding.**\n",
    "\n",
    "A vector of integers (representing a set of documents) where each integer corresponds to a word string. Similar to the case above with random integers, but now we can add labels to denote positive and negative sentiment.\n",
    "We now train a word embedding constrained by a loss function that aims for _maximum separation of the documents_.\n",
    "Note that the difference between the cell above and a trained embedding layer is the addition of a loss function that aims to maximize discriminability of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we\n"
     ]
    }
   ],
   "source": [
    "count_vect.vocabulary_\n",
    "print(list(count_vect.vocabulary_.keys())[list(count_vect.vocabulary_.values()).index(96)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "data = pd.read_csv('../Data/Restaurant_Reviews.tsv', sep='\\t',  encoding = \"ISO-8859-1\")\n",
    "data.iloc[:700].to_csv('../Data/RestaurantReviews_training.tsv', sep='\\t', index=False, header=False)\n",
    "data.iloc[700:].to_csv('../Data/RestaurantReviews_test.tsv', sep='\\t', index=False, header=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def save_embedding(outputFile, weights, vocabulary):\n",
    "    '''\n",
    "    This function saves a text file containing each word in the vocabulary and the embedding weights that were learned in the model.\n",
    "\n",
    "    :param outputFile:\n",
    "    :param weights:\n",
    "    :param vocabulary:\n",
    "    :return:\n",
    "    '''\n",
    "    rev = {v:k for k, v in vocabulary.items()} # reverses the dictionary from words --> integer to go from integer --> words\n",
    "    with codecs.open(outputFile, \"w\") as f:\n",
    "        f.write(str(len(vocabulary)) + \" \" + str(weights.shape[1]) + \"\\n\")\n",
    "        for index in sorted(rev.keys()):\n",
    "            word=rev[index]\n",
    "            f.write(word + \" \")\n",
    "            for i in range(len(weights[index])):\n",
    "                f.write(str(weights[index][i]) + \" \")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "\n",
    "def getLines(f):\n",
    "    ''' Given a path to a .tsv file, this function returns a list of strings corresponding to each row of the .tsv file.\n",
    "    Columns are joined together in a single string per row separated by \\t (denoting a tab) '''\n",
    "    lines = [line.rstrip() for line in open(f)]\n",
    "    return lines\n",
    "\n",
    "\n",
    "\n",
    "def create_vocabulary(vocabulary, sentences):\n",
    "    '''\n",
    "\n",
    "    :param vocabulary: an empty dictionary\n",
    "    :param sentences: a list of strings representing the rows of the .tsv file containing restaurant review data\n",
    "    :return: a dictionary mapping every unique word in the sentences list, to an integer\n",
    "    '''\n",
    "    vocabulary[\"<unk>\"]=0\n",
    "    for sentence in sentences: #for each row in the .tsv data file\n",
    "        for word in sentence.strip().split(): # each row is a string that is split into a list of words\n",
    "            word=re.sub(\"[.,:;'\\\"!?()]+\",\"\",word.lower()) # replace special characters with nothing, and make all words lowercase\n",
    "            if word not in vocabulary: # make sure each word is unique\n",
    "                vocabulary[word]=len(vocabulary) # assign an integer to the word\n",
    "\n",
    "\n",
    "def process_training_data(textFile,max_len):\n",
    "    data=[]\n",
    "    sentences = getLines(textFile) # a list of strings where each string corresponds to a row from the input textfile.\n",
    "    vocab = dict()\n",
    "    labels=[]\n",
    "    create_vocabulary(vocab, sentences) # a dictionary mapping every unique word in the sentences list, to an integer\n",
    "    for s in sentences: # each s in sentences is one string consisting of a review AND a boolean label of positive or negative.\n",
    "        words=[]\n",
    "        m=re.match(\"^([^\\t]+)\\t(.+)$\",s.rstrip())  # searches the string for a \"\\t\"\n",
    "        if m:\n",
    "            sentence=m.group(1) # first group is the text of the review (before the \"\\t\")\n",
    "            labels.append(int(m.group(2))) # second group (comes after \\t of the string, s) is the label\n",
    "            for w in sentence.split(\" \"):\n",
    "                w=re.sub(\"[.,:;'\\\"!?()]+\",\"\",w.lower()) # removes special characters, and makes everything lowercase\n",
    "                if w!='': # if there are words left\n",
    "                    words.append(vocab[w]) # append the integer from the vocabulary that represents word, w.\n",
    "        data.append(words)\n",
    "    data = pad_sequences(data, maxlen=max_len, padding='post') # pad with zeros so vectors are all the same length\n",
    "\n",
    "    return data,labels, vocab\n",
    "\n",
    "\n",
    "def process_test_data(textFile,vocab,max_len):\n",
    "    data=[]\n",
    "    sentences = getLines(textFile) # a list of strings where each string corresponds to a row from the input textfile.\n",
    "    labels=[]\n",
    "    create_vocabulary(vocab, sentences) # a dictionary mapping every unique word in the sentences list, to an integer\n",
    "    for s in sentences: # each s in sentences is one string consisting of a review AND a boolean label of positive or negative.\n",
    "        words=[]\n",
    "        m=re.match(\"^([^\\t]+)\\t(.+)$\",s.rstrip()) # searches the string for a \"\\t\"\n",
    "        if m:\n",
    "            sentence=m.group(1) # first group is the text of the review (before the \"\\t\")\n",
    "            labels.append(int(m.group(2))) # second group (comes after \\t of the string, s) is the label\n",
    "            for w in sentence.split(\" \"):\n",
    "                w=re.sub(\"[.,:;'\\\"!?()]+\",\"\",w.lower()) # removes special characters, and makes everything lowercase\n",
    "                if w!='': # if there are words left\n",
    "                    if w in vocab:\n",
    "                        words.append(vocab[w]) # append the integer from the vocabulary that represents word, w.\n",
    "                    else:\n",
    "                        words.append(vocab[\"<unk>\"])\n",
    "        data.append(words)\n",
    "    data = pad_sequences(data, maxlen=max_len, padding='post')\n",
    "    return data,labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/f005dm6/.conda/envs/DL4NLP/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      "700/700 [==============================] - 1s 746us/step - loss: 0.6967 - acc: 0.5357\n",
      "Epoch 2/100\n",
      "700/700 [==============================] - 0s 243us/step - loss: 0.6622 - acc: 0.5614\n",
      "Epoch 3/100\n",
      "700/700 [==============================] - 0s 232us/step - loss: 0.6297 - acc: 0.7143\n",
      "Epoch 4/100\n",
      "700/700 [==============================] - 0s 233us/step - loss: 0.5640 - acc: 0.7700\n",
      "Epoch 5/100\n",
      "700/700 [==============================] - 0s 231us/step - loss: 0.4704 - acc: 0.8843\n",
      "Epoch 6/100\n",
      "700/700 [==============================] - 0s 246us/step - loss: 0.3717 - acc: 0.9429\n",
      "Epoch 7/100\n",
      "700/700 [==============================] - 0s 250us/step - loss: 0.2824 - acc: 0.9643\n",
      "Epoch 8/100\n",
      "700/700 [==============================] - 0s 251us/step - loss: 0.2143 - acc: 0.9814\n",
      "Epoch 9/100\n",
      "700/700 [==============================] - 0s 227us/step - loss: 0.1630 - acc: 0.9900\n",
      "Epoch 10/100\n",
      "700/700 [==============================] - 0s 249us/step - loss: 0.1265 - acc: 0.9929\n",
      "Epoch 11/100\n",
      "700/700 [==============================] - 0s 228us/step - loss: 0.1002 - acc: 0.9943\n",
      "Epoch 12/100\n",
      "700/700 [==============================] - 0s 228us/step - loss: 0.0807 - acc: 0.9971\n",
      "Epoch 13/100\n",
      "700/700 [==============================] - 0s 240us/step - loss: 0.0666 - acc: 0.9971\n",
      "Epoch 14/100\n",
      "700/700 [==============================] - 0s 284us/step - loss: 0.0546 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "700/700 [==============================] - 0s 238us/step - loss: 0.0456 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "700/700 [==============================] - 0s 243us/step - loss: 0.0387 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "700/700 [==============================] - 0s 225us/step - loss: 0.0334 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "700/700 [==============================] - 0s 239us/step - loss: 0.0286 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "700/700 [==============================] - 0s 241us/step - loss: 0.0253 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "700/700 [==============================] - 0s 248us/step - loss: 0.0221 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "700/700 [==============================] - 0s 230us/step - loss: 0.0196 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "700/700 [==============================] - 0s 230us/step - loss: 0.0175 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "700/700 [==============================] - 0s 228us/step - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "700/700 [==============================] - 0s 232us/step - loss: 0.0141 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "700/700 [==============================] - 0s 234us/step - loss: 0.0129 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "700/700 [==============================] - 0s 263us/step - loss: 0.0116 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "700/700 [==============================] - 0s 230us/step - loss: 0.0106 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "700/700 [==============================] - 0s 234us/step - loss: 0.0097 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "700/700 [==============================] - 0s 226us/step - loss: 0.0089 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "700/700 [==============================] - 0s 224us/step - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "700/700 [==============================] - 0s 228us/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "700/700 [==============================] - 0s 232us/step - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "700/700 [==============================] - 0s 227us/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "700/700 [==============================] - 0s 231us/step - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "700/700 [==============================] - 0s 238us/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "700/700 [==============================] - 0s 226us/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "700/700 [==============================] - 0s 236us/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "700/700 [==============================] - 0s 232us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "700/700 [==============================] - 0s 232us/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "700/700 [==============================] - 0s 228us/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "700/700 [==============================] - 0s 231us/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "700/700 [==============================] - 0s 227us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "700/700 [==============================] - 0s 228us/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "700/700 [==============================] - 0s 230us/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "700/700 [==============================] - 0s 230us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "700/700 [==============================] - 0s 228us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "700/700 [==============================] - 0s 226us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "700/700 [==============================] - 0s 227us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "700/700 [==============================] - 0s 227us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "700/700 [==============================] - 0s 229us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "700/700 [==============================] - 0s 229us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "700/700 [==============================] - 0s 236us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "700/700 [==============================] - 0s 229us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "700/700 [==============================] - 0s 232us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "700/700 [==============================] - 0s 231us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "700/700 [==============================] - 0s 235us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "700/700 [==============================] - 0s 226us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "700/700 [==============================] - 0s 226us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "700/700 [==============================] - 0s 242us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "700/700 [==============================] - 0s 239us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "700/700 [==============================] - 0s 239us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "700/700 [==============================] - 0s 228us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "700/700 [==============================] - 0s 225us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "700/700 [==============================] - 0s 223us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "700/700 [==============================] - 0s 231us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "700/700 [==============================] - 0s 230us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "700/700 [==============================] - 0s 227us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "700/700 [==============================] - 0s 227us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "700/700 [==============================] - 0s 223us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "700/700 [==============================] - 0s 223us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "700/700 [==============================] - 0s 224us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "700/700 [==============================] - 0s 225us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "700/700 [==============================] - 0s 222us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "700/700 [==============================] - 0s 228us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "700/700 [==============================] - 0s 223us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "700/700 [==============================] - 0s 227us/step - loss: 9.7367e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "700/700 [==============================] - 0s 222us/step - loss: 9.4473e-04 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "700/700 [==============================] - 0s 225us/step - loss: 9.1649e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "700/700 [==============================] - 0s 227us/step - loss: 8.9130e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "700/700 [==============================] - 0s 242us/step - loss: 8.6531e-04 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "700/700 [==============================] - 0s 227us/step - loss: 8.4078e-04 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "700/700 [==============================] - 0s 223us/step - loss: 8.1795e-04 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "700/700 [==============================] - 0s 224us/step - loss: 7.9482e-04 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "700/700 [==============================] - 0s 223us/step - loss: 7.7240e-04 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "700/700 [==============================] - 0s 226us/step - loss: 7.5214e-04 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "700/700 [==============================] - 0s 240us/step - loss: 7.3102e-04 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "700/700 [==============================] - 0s 243us/step - loss: 7.1138e-04 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "700/700 [==============================] - 0s 226us/step - loss: 6.9376e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "700/700 [==============================] - 0s 227us/step - loss: 6.7516e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "700/700 [==============================] - 0s 231us/step - loss: 6.5866e-04 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "700/700 [==============================] - 0s 415us/step - loss: 6.4063e-04 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "700/700 [==============================] - 0s 246us/step - loss: 6.2454e-04 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "700/700 [==============================] - 0s 242us/step - loss: 6.0897e-04 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "700/700 [==============================] - 0s 234us/step - loss: 5.9342e-04 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "700/700 [==============================] - 0s 243us/step - loss: 5.7846e-04 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "700/700 [==============================] - 0s 629us/step - loss: 5.6475e-04 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "700/700 [==============================] - 0s 449us/step - loss: 5.5131e-04 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "700/700 [==============================] - 0s 243us/step - loss: 5.3737e-04 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "700/700 [==============================] - 0s 255us/step - loss: 5.2562e-04 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "700/700 [==============================] - 0s 236us/step - loss: 5.1204e-04 - acc: 1.0000\n",
      "0.7133333086967468\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dat_path = '../Data/RestaurantReviews_training.tsv'\n",
    "test_dat_path = '../Data/RestaurantReviews_test.tsv'\n",
    "\n",
    "max_len=100\n",
    "data,labels,vocab=process_training_data(train_dat_path, max_len)\n",
    "test_data,test_labels=process_test_data(test_dat_path,vocab,max_len)\n",
    "\n",
    "model = Sequential()\n",
    "embedding=Embedding(len(vocab), 100, input_length=max_len)\n",
    "model.add(embedding)\n",
    "model.add(Flatten()) # flattens a multidimensional embedding into a one-dimensional string\n",
    "model.add(Dense(units=1,activation=\"sigmoid\"))  # units=1 is the dimensionality of the output space\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc'])\n",
    "model.fit(data,labels,epochs=100, verbose=1) # an epoch is an iteration; leave one out cross-validation\n",
    "\n",
    "loss, accuracy = model.evaluate(test_data, test_labels, verbose=0)\n",
    "print(accuracy)\n",
    "\n",
    "save_embedding(\"embedding_labeled.txt\", embedding.get_weights()[0], vocab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that we have learned embeddings for each word in the vocabulary, we can look at nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors # gensime is a topic modeling package\n",
    "import gensim.models\n",
    "import os\n",
    "\n",
    "w2v = gensim.models.KeyedVectors.load_word2vec_format('embedding_labeled.txt', binary=False, unicode_errors='ignore')\n",
    "\n",
    "for w in  sorted(w2v.wv.vocab):\n",
    "    print(w,w2v.most_similar(w,topn=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.2 From Words to Vectors: word2vec\n",
    "\n",
    "The Word2Vec algorithm is a procedural (learned) embedding. The vector representations of words obtained with Word2Vec express similarities between words based on their context: the words that share similar contexts end up having similar numerical vector representations.\n",
    "\n",
    "In our example, we wll use Word2Vec to predict contexts from words, in order to build a tool that suggests synonyms in an editor. For instance, given a string like “the restaurant has a terrible ambiance and the food is awful” we want to predict if the words ‘terrible’ for ‘restaurant’ and ‘awful’ for ‘food’ are valid context words.\n",
    "\n",
    "To do that, we need both positive and negative examples of surrounding contexts. To get negative examples, we use the procedure called “negative sampling”. First, we map words to integers. Second, using a random generator and a fixed context window size, we sample positive examples, as well as negative ones. This produces couples of integers (input word, context word) and associated labels - 0 for an invalid context and 1 for a valid one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import skipgrams\n",
    "\n",
    "sentence = \"the restaurant has a terrible ambiance and the food is awful\"\n",
    "sequence=[vocab[w] for w in sentence.split(\" \")]\n",
    "vocab = dict()\n",
    "create_vocabulary(vocab, sentence)\n",
    "skipgrams(sequence, 100, window_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Processing data for Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Reshape, dot\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.sequence import skipgrams\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import random\n",
    "import re\n",
    "import codecs\n",
    "\n",
    "def save_embeddings(save_filepath, weights, vocabulary):\n",
    "        rev = {v:k for k, v in vocabulary.items()}\n",
    "        with codecs.open(save_filepath, \"w\") as f:\n",
    "            f.write(str(len(vocabulary)) + \" \" + str(weights.shape[1]) + \"\\n\")\n",
    "            for index in sorted(rev.keys()):\n",
    "                word=rev[index]\n",
    "                f.write(word + \" \")\n",
    "                for i in range(len(weights[index])):\n",
    "                    f.write(str(weights[index][i]) + \" \")\n",
    "                    f.write(\"\\n\")\n",
    "\n",
    "\n",
    "def getLines(f):\n",
    "    lines = [line.rstrip() for line in open(f)]\n",
    "    return lines\n",
    "\n",
    "\n",
    "# a function that loops over skipgrams (created by process_data function below) during the training phase of the model,\n",
    "# picking out random samples and labels and feeding them as batches to the model.\n",
    "def generator(target,context, labels, batch_size):\n",
    "    batch_target = np.zeros((batch_size, 1))\n",
    "    batch_context = np.zeros((batch_size, 1))\n",
    "    batch_labels = np.zeros((batch_size,1))\n",
    "\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            index= random.randint(0,len(target)-1)\n",
    "            batch_target[i] = target[index]\n",
    "            batch_context[i]=context[index]\n",
    "            batch_labels[i] = labels[index]\n",
    "        yield [batch_target,batch_context], [batch_labels]\n",
    "\n",
    "# a function for processing raw data (plain sentences) for skipgrams, and collecting all skupgrams and their labels for the entire dataset\n",
    "def process_data(textFile,window_size):\n",
    "    couples=[] # for pairs of words: input word and context word\n",
    "    labels=[] # for their labels\n",
    "    sentences = getLines(textFile)\n",
    "    vocab = dict()\n",
    "    create_vocabulary(vocab, sentences)\n",
    "    vocab_size=len(vocab)\n",
    "    for s in sentences:\n",
    "        words=[]\n",
    "        for w in s.split(\" \"):\n",
    "            w=re.sub(\"[.,:;'\\\"!?()]+\",\"\",w.lower())\n",
    "            if w!='':\n",
    "                words.append(vocab[w])\n",
    "        c,l=skipgrams(words,vocab_size,window_size=window_size) # creating skupgrams - word pairs with corresponding labels.\n",
    "        couples.extend(c)\n",
    "        labels.extend(l)\n",
    "    return vocab,couples,labels\n",
    "\n",
    "\n",
    "def  create_vocabulary(vocabulary, sentences):\n",
    "    vocabulary[\"<unk>\"]=0\n",
    "    for sentence in sentences:\n",
    "        for word in sentence.strip().split():\n",
    "            word=re.sub(\"[.,:;'\\\"!?()]+\",\"\",word.lower())\n",
    "            if word not in vocabulary:\n",
    "                vocabulary[word]=len(vocabulary)\n",
    "\n",
    "\n",
    "window_size = 3\n",
    "vector_dim = 100\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "file_path = 'embedding_labeled.txt'\n",
    "vocab,couples,labels=process_data(file_path,window_size)\n",
    "\n",
    "vocab_size=len(vocab)\n",
    "\n",
    "# Splitting the generated couples into the target words (input) and the context words.\n",
    "word_target, word_context = zip(*couples)\n",
    "word_target = np.array(word_target, dtype=\"int32\")\n",
    "word_context = np.array(word_context, dtype=\"int32\")\n",
    "\n",
    "# Targets and contexts consist of one-dimensional input layers.\n",
    "input_target = Input((1,))\n",
    "input_context = Input((1,))\n",
    "\n",
    "# Our embedding accepts inputs of size 1 and maps them to vectors of size vector_dim, and does it for a total of vocab_size different words.\n",
    "embedding = Embedding(vocab_size, vector_dim, input_length=1, name='embedding')\n",
    "# Embedding the targets and reshaping them to the desired vector length.\n",
    "target = embedding(input_target)\n",
    "target = Reshape((vector_dim, 1))(target)\n",
    "# Embedding the contexts and reshaping them to the desired vector length.\n",
    "context = embedding(input_context)\n",
    "context = Reshape((vector_dim, 1))(context)\n",
    "\n",
    "# Calculating the dot product of the target and context vectors. This dot product is an intermediate representation upon which the final classification (whether for a given target word the context word is valid or not).\n",
    "dot_product = dot([target, context], axes=1)\n",
    "dot_product = Reshape((1,))(dot_product)\n",
    "output = Dense(1, activation='sigmoid')(dot_product)\n",
    "model = Model(input=[input_target, input_context], output=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "epochs=int(1)\n",
    "\n",
    "# Feeding random batches (100 cases each) of target words, context words and labels, for 1000 epochs. Every epoch carries 100 optimization steps.\n",
    "model.fit_generator(generator(word_target, word_context,labels,100), steps_per_epoch=100, epochs=epochs)\n",
    "\n",
    "#Extracting the per-word weights from the shared embedding. These weights constitute the Word2Vec embedding for the input words.\n",
    "save_embeddings(\"embedding.txt\", embedding.get_weights()[0], vocab)\n",
    "\n",
    "exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# These are my Lovely Additions I really know Deep Learning and NLP and Github. Please hire/save me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.3 From Documents to Vector: doc2vec\n",
    "\n",
    "a random thing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3713jvsc74a57bd011645b4c5e807595040182e353e47770cd2ac171a641d7dab885eb92ea00a149",
   "language": "python",
   "display_name": "Python 3.7.13 ('DL4NLP')"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}